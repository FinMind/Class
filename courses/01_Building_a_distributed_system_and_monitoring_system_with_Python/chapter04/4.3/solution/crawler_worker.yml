version: '3.8'
services:
  crawler_twse:
    # 設定 image
    image: linsamtw/class01_crawler:dev
    # 設定 hostname, 用於 flower 上顯示
    hostname: "{{.Node.Hostname}}-{{.Service.Name}}"
    # 啟動 worker 指令
    command: pipenv run celery -A financialdata.worker worker --loglevel=info --concurrency=1  --hostname=%h.twse -Q twse
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      placement:
        # 設定, 最多只能啟動一個 services 在 node 中
        # 如果一個 node 啟動兩個以上的 crawler_twse 工人
        # 等於同時用這台 node 的 IP, 對證交所連續爬蟲
        # 會被 ban
        max_replicas_per_node: 1
        # 設定 node 的 label, 只會在
        # 有設定 label crawler_twse = true 的機器上
        # 啟動該 services
        constraints: [node.labels.crawler_twse == true]
    restart: always
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

  crawler_tpex:
    # 設定 image
    image: linsamtw/class01_crawler:dev
    # 設定 hostname, 用於 flower 上顯示
    hostname: "{{.Node.Hostname}}-{{.Service.Name}}"
    # 啟動 worker 指令
    command: pipenv run celery -A financialdata.worker worker --loglevel=info --concurrency=1  --hostname=%h.tpex -Q tpex
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      placement:
        # 設定, 最多只能啟動一個 services 在 node 中
        # 如果一個 node 啟動兩個以上的 crawler_tpex 工人
        # 等於同時用這台 node 的 IP, 對證交所連續爬蟲
        # 會被 ban
        max_replicas_per_node: 1
        # 設定 node 的 label, 只會在
        # 有設定 label crawler_tpex = true 的機器上
        # 啟動該 services
        constraints: [node.labels.crawler_tpex == true]
    restart: always
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

  crawler_taifex:
    # 設定 image
    image: linsamtw/class01_crawler:dev
    # 設定 hostname, 用於 flower 上顯示
    hostname: "{{.Node.Hostname}}-{{.Service.Name}}"
    # 啟動 worker 指令
    command: pipenv run celery -A financialdata.worker worker --loglevel=info --concurrency=1  --hostname=%h.taifex -Q taifex
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      placement:
        # 設定, 最多只能啟動一個 services 在 node 中
        # 如果一個 node 啟動兩個以上的 crawler_taifex 工人
        # 等於同時用這台 node 的 IP, 對證交所連續爬蟲
        # 會被 ban
        max_replicas_per_node: 1
        # 設定 node 的 label, 只會在
        # 有設定 label crawler_taifex = true 的機器上
        # 啟動該 services
        constraints: [node.labels.crawler_taifex == true]
    restart: always
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network
       
networks:
  my_network:
    # 加入已經存在的網路
    external: true
